00:13:16-00:13:30 Tom: 这个思路很好，不过他们是怎么处理多人同时说话的情况的？
00:13:31-00:14:15 Andy: 他们用了一个叫 Speaker Diarization 的技术，可以识别不同说话人。不过目前还在优化阶段，特别是在处理重叠说话的情况。他们团队的李工说，正在尝试用 Transformer 架构来改进这个问题。
00:14:16-00:15:30 Tom: 我听说他们还在测试一个叫 VAD（Voice Activity Detection）的技术，可以更准确地检测语音活动。这个技术对降噪也很有帮助。
00:15:31-00:16:45 Andy: 这个技术很实用。
00:16:46-00:17:00 Tom: 本地部署的话，硬件要求高吗？
00:17:01-00:17:15 Andy: 如果用蒸馏后的小模型，一台普通的服务器就能跑起来。他们测试过，8 核 CPU，32GB 内存的机器就能支持 10 个并发转写。
00:17:16-00:18:30 Tom: 那我们可以先做个 POC，用云服务快速验证一下效果。如果效果不错，再考虑本地部署。对了，说到数据安全，同声传译团队是怎么处理的？
00:18:31-00:18:45 Lily: 这是个好问题。
00:18:46-00:19:30 Tom: 他们用了数据加密和访问控制，所有录音和转写结果都存储在加密的存储桶里。而且他们还在开发一个数据脱敏功能，可以自动识别和脱敏敏感信息。
00:19:31-00:20:45 Lily: 这个功能很实用。不过说到开发周期，你们觉得大概需要多长时间？我觉得可以先做个简单的版本，支持基本的语音转写功能。
00:20:46-00:22:00 Andy: 如果只做基础功能的话，我觉得两周应该够了。我们可以先用同声传译团队的基础设施，这样可以节省很多时间。不过我觉得在开始开发之前，我们应该先做个简单的用户测试，收集一些真实的会议录音。
00:22:01-00:22:15 Tom: 两周时间够吗？
00:22:16-00:23:00 Andy: 如果只做最基础的功能，应该没问题。我们可以先实现核心功能，其他功能后续迭代。
00:23:01-00:24:15 Tom: 我同意，两周时间比较合理。不过我觉得在开始开发之前，我们是不是应该先和同声传译团队开个技术对接会？了解一下他们的技术细节和最佳实践。
00:24:16-00:24:30 Lily: 这个建议很好，我来安排。
00:24:31-00:24:45 Tom: 好的，谢谢。
00:24:46-00:25:45 Lily: 那我们先定个时间？我觉得可以安排在下周二，这样大家都有时间准备。另外，我觉得可以邀请他们团队的王工和李工一起来，他们负责模型训练和优化，经验很丰富。
00:25:46-00:27:00 Tom: 没问题，我这边时间都可以。对了，我听说他们团队最近在做一个新的功能，可以自动提取会议中的关键信息，比如决策点、待办事项这些。我们要不要也考虑加入这个功能？
00:27:01-00:27:15 Andy: 这个功能很实用。
